# Mini WebUI para Ollama (HTML + JavaScript)

Una interfaz WebUI minimalista, port√°til y completamente offline para interactuar con modelos de **Ollama ejecut√°ndose en WSL** (Windows Subsystem for Linux) desde cualquier navegador en Windows.

Este proyecto no usa frameworks, backend ni dependencias externas.  
Toda la l√≥gica est√° implementada en un √∫nico archivo `index.html`.

---

## üöÄ Caracter√≠sticas principales

- Selecci√≥n de modelos instalados en Ollama.
- Panel informativo con:
  - N√∫mero de par√°metros (`parameter_size`)
  - Tama√±o en disco (GB)
  - Quantization (`Q4`, `Q5`, `Q8`, etc.) + explicaci√≥n autom√°tica
  - Latencia promedio del **primer token**
- Env√≠o de prompts con **streaming palabra por palabra**.
- Bot√≥n para **detener streaming**.
- Bot√≥n para **limpiar historial**.
- Modo respuesta corta (<10 palabras).
- Modo forzar castellano.
- Modal de ayuda integrado.
- Funciona en Windows / WSL / Linux.
- Completamente offline una vez instalados los modelos.
- Sin dependencias externas.

---

## üì¶ Requisitos del sistema

## üñ•Ô∏è Requisitos del sistema (Windows)

- ü™ü **Windows 10 / 11**  
- üêß **WSL** (Ubuntu recomendado)  
- üêç **Python 3**  
- üåê **Navegador web compatible:**  
  - ü¶ä **Firefox** ‚Üí Permite abrir `index.html` directamente *(sin servidor)*  
  - üåê **Chrome / Edge** ‚Üí Requieren servidor local *(por pol√≠ticas de seguridad)*  

---

## ‚ùì ¬øPor qu√© Chrome y Edge necesitan un servidor Python?

Chrome y Edge **bloquean por razones de seguridad** cualquier intento de usar `fetch()` desde un archivo abierto localmente:

```
file://C:/ruta/index.html
```

cuando intenta comunicarse con:

```
http://localhost:11434     ‚Üê donde corre Ollama
```

Este bloqueo forma parte de las reglas del navegador conocidas como:

### üîí CORS + Same-Origin Policy

Estas pol√≠ticas impiden que un archivo HTML local trate de hacer solicitudes HTTP a un origen distinto del suyo.  
Por eso obtienes el error:

```
TypeError: Failed to fetch
```

**No es un fallo de tu WebUI.**  
Es una protecci√≥n del navegador.

---

## ‚úÖ Soluci√≥n: usar un servidor Python local

Chrome y Edge permiten solicitudes HTTP **solo si la p√°gina fue servida por un servidor real**, aunque sea local.

La forma m√°s simple es:

```bash
python3 -m http.server 8000
```

Esto expone tus archivos en:

```
http://localhost:8000
```

Ahora s√≠ tu WebUI puede comunicarse con:

```
http://localhost:11434   ‚Üê API de Ollama
```

Y todo funciona perfectamente.

---

## üìù Resumen r√°pido

| Navegador | ¬øPuede abrir index.html sin servidor? | Motivo |
|----------|----------------------------------------|--------|
| ü¶ä **Firefox** | ‚úîÔ∏è S√≠ | Pol√≠ticas menos estrictas para `file://` |
| üåê **Chrome**  | ‚ùå No | Bloqueo CORS/Same-Origin |
| üü¶ **Edge**    | ‚ùå No | Bloqueo CORS/Same-Origin |

---

## üí° Nota Final

El servidor Python **solo entrega archivos est√°ticos**.  
No ejecuta c√≥digo, no procesa la l√≥gica.  

Toda la inteligencia ocurre en:

- üß† **Ollama corriendo en WSL**
- ‚öôÔ∏è **API local: `http://localhost:11434`**
- üñ•Ô∏è **Tu WebUI HTML (index.html)**


## üêß Instalaci√≥n de WSL

```
wsl --install
```

---

## ü§ñ Instalaci√≥n de Ollama dentro de WSL

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
```

API en:

```
http://localhost:11434
```

---

## üì• Descargar modelos (el que le guste, o varios de ellos)

```bash
ollama pull gemma3:4b
ollama pull llama3.2:3b
ollama pull mistral:7b
```

---

## üåê Ejecutar la Mini WebUI

```
python3 -m http.server 8000
```

Entrar luego en:

```
http://localhost:8000
```

---

## üîå API usada

- `/api/tags`
- `/api/show`
- `/api/generate` (stream)

---

## üìù Licencia MIT

Autor: **Rommel Contreras**  
Blog: https://tecnologiacumanesa.blogspot.com/

